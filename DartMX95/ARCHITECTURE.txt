================================================================================
                    WYZECAR - DART MX95 + SONATA CARRIER
                         ROS2 Vision Tracking Platform
================================================================================

GOAL: Vision-based human tracking and following using ROS2

================================================================================
                          HARDWARE OVERVIEW
================================================================================

DART-MX95 SoM (NXP i.MX 95)
---------------------------
  CPU: Up to 6x Arm Cortex-A55 @ 2.0GHz
  Real-time: Cortex-M7 @ 800MHz + Cortex-M33 @ 333MHz
  NPU: Dedicated AI/ML accelerator for vision inference
  Memory: Up to 8GB LPDDR5
  Connectivity: Dual GbE, 10GbE, Wi-Fi 6, BT 5.3, CAN FD
  Interfaces: MIPI-CSI (camera), PCIe Gen 3, USB 3.0

Sonata Carrier Board
--------------------
  - 2x MIPI-CSI camera connectors
  - 2x CAN Bus
  - 2x Gigabit Ethernet (RJ45)
  - M.2 connectors for expansion
  - SD Card slot
  - Audio (mic, headphone, line-in)
  - GPIO header with PWM-capable pins
  - USB ports

================================================================================
                          CAMERA OPTIONS
================================================================================

OPTION 1: CAM2C CUM10330_MOD (e-con Systems based) [SELECTED]
-------------------------------------------------------------
  Sensor: AR0330 (onsemi)
  Resolution: 3.4MP (2304x1536)
  Frame rates: 1080p @ 60fps, 3.4MP @ 50fps
  Interface: USB-C (via attached ISP/adapter board)
  Features: Onboard ISP, auto white balance, auto exposure
  Low-light: Good (designed for low-light applications)
  Size: 30mm x 30mm

  Pros: Good low-light, onboard ISP handles image processing,
        USB-C connection is simpler than MIPI ribbon cable
  Cons: May be older/discontinued model

OPTION 2: ADRIA_290_MOD REV X1
------------------------------
  (Could not find public specs - may be custom/internal part)
  Recommend: Check Variscite documentation or contact support

RECOMMENDATION: Start with CUM10330_MOD
  - 1080p @ 60fps is plenty for human tracking
  - Onboard ISP reduces CPU load
  - MIPI interface is native to i.MX95

For human tracking, 1080p @ 30fps is sufficient. Higher resolution
helps with detecting humans at greater distances.

================================================================================
                          SOFTWARE STACK
================================================================================

Host OS: Debian (on Dart MX95)
Container: Ubuntu 22.04 + ROS2 Humble (Docker)

    +--------------------------------------------------+
    |                   Debian (Host)                  |
    |  +--------------------------------------------+  |
    |  |         Docker: Ubuntu 22.04              |  |
    |  |  +--------------------------------------+  |  |
    |  |  |           ROS2 Humble                |  |  |
    |  |  |                                      |  |  |
    |  |  |  +----------+  +------------------+  |  |  |
    |  |  |  | Camera   |  | Motor Control    |  |  |  |
    |  |  |  | Node     |  | Node             |  |  |  |
    |  |  |  +----------+  +------------------+  |  |  |
    |  |  |                                      |  |  |
    |  |  |  +----------+  +------------------+  |  |  |
    |  |  |  | Human    |  | Navigation/      |  |  |  |
    |  |  |  | Detector |  | Following Node   |  |  |  |
    |  |  |  +----------+  +------------------+  |  |  |
    |  |  +--------------------------------------+  |  |
    |  +--------------------------------------------+  |
    +--------------------------------------------------+

================================================================================
                       ROS2 ARCHITECTURE
================================================================================

NODES:
------

1. camera_node
   - Publishes: /image_raw (sensor_msgs/Image)
   - Publishes: /camera_info (sensor_msgs/CameraInfo)
   - Uses: v4l2_camera or custom MIPI driver

2. human_detector_node
   - Subscribes: /image_raw
   - Publishes: /detections (vision_msgs/Detection2DArray)
   - Publishes: /target_person (geometry_msgs/PointStamped)
   - Uses: YOLOv8-nano, MobileNet-SSD, or MediaPipe
   - Can leverage i.MX95 NPU for acceleration

3. motor_controller_node
   - Subscribes: /cmd_vel (geometry_msgs/Twist)
   - Controls: L298N via GPIO/PWM
   - Controls: Steering servo via PWM
   - Publishes: /motor_status

4. follower_node
   - Subscribes: /target_person
   - Publishes: /cmd_vel
   - Implements: PID control to follow detected human
   - Maintains: Safe following distance

TOPICS:
-------
  /image_raw          Camera images
  /detections         All detected objects
  /target_person      Position of person to follow
  /cmd_vel            Velocity commands (linear.x, angular.z)
  /motor_status       Motor feedback

================================================================================
                       MOTOR CONTROL OPTIONS
================================================================================

OPTION A: Direct GPIO/PWM from Dart MX95 (Recommended)
------------------------------------------------------
  - Use Linux sysfs PWM interface
  - PWM for L298N ENA/ENB (motor speed)
  - GPIO for L298N IN1-IN4 (motor direction)
  - PWM for steering servo (50Hz, 1-2ms pulse)

  Pros: No extra hardware, lowest latency
  Cons: Need to map PWM pins on Sonata carrier

  Implementation:
    - libgpiod for GPIO control
    - /sys/class/pwm/ for PWM control
    - Or use pigpio-like library for i.MX

OPTION B: Microcontroller Bridge (ESP32/Arduino)
------------------------------------------------
  - Dart sends commands over UART/USB
  - Microcontroller handles real-time PWM
  - Similar to CubeOrangePlus approach

  Pros: Proven approach, real-time guarantees
  Cons: Extra hardware, added complexity

OPTION C: ROS2 micro-ROS on Cortex-M7
-------------------------------------
  - Run micro-ROS on the i.MX95's built-in Cortex-M7
  - M7 handles real-time motor control
  - Communicates with A55 cores via shared memory

  Pros: No extra hardware, hard real-time
  Cons: More complex setup, requires RTOS on M7

RECOMMENDATION: Start with Option A (Direct GPIO/PWM)
  - Simplest to implement
  - Can upgrade to Option C later if needed

================================================================================
                       PWM CONTROL (LINUX SYSFS)
================================================================================

Servo PWM (50Hz, 1-2ms pulse):
  Period: 20ms (20,000,000 ns)
  Duty cycle:
    - 0°:   0.5ms  =  2.5% = 500,000 ns
    - 90°:  1.5ms  =  7.5% = 1,500,000 ns
    - 180°: 2.5ms  = 12.5% = 2,500,000 ns

Motor PWM (L298N):
  Frequency: 1-20kHz typical (use ~1kHz to start)
  Period: 1ms (1,000,000 ns)
  Duty cycle: 0-100% for speed control

Linux PWM sysfs example:
  echo 0 > /sys/class/pwm/pwmchip0/export
  echo 20000000 > /sys/class/pwm/pwmchip0/pwm0/period
  echo 1500000 > /sys/class/pwm/pwmchip0/pwm0/duty_cycle
  echo 1 > /sys/class/pwm/pwmchip0/pwm0/enable

================================================================================
                       WIRING (SIMILAR TO CUBE SETUP)
================================================================================

POWER:
  Wall adapter --> Dart MX95 (for now)
  Lab PSU (0-30V, 0-10A) --> L298N +12V

L298N TO DART (via Sonata GPIO header):
  ENA  <-- PWM pin (Motor 1 speed)
  IN1  <-- GPIO (Motor 1 direction)
  IN2  <-- GPIO (Motor 1 direction)
  IN3  <-- GPIO (Motor 2 direction)
  IN4  <-- GPIO (Motor 2 direction)
  ENB  <-- PWM pin (Motor 2 speed)
  GND  <-- Common ground

STEERING SERVO:
  Signal <-- PWM pin (50Hz servo signal)
  5V     <-- L298N 5V output (or separate 5V)
  GND    <-- Common ground

CAMERA:
  USB-C cable from CUM10330_MOD to Sonata USB-C port

IMPORTANT: Identify available PWM pins on Sonata carrier.
Check device tree: /sys/class/pwm/ after boot.

================================================================================
                       DOCKER SETUP
================================================================================

Dockerfile (Ubuntu 22.04 + ROS2 Humble):

  FROM arm64v8/ubuntu:22.04

  # Install ROS2 Humble
  RUN apt update && apt install -y locales curl gnupg2 lsb-release
  RUN curl -sSL https://raw.githubusercontent.com/ros/rosdistro/master/ros.key \
      -o /usr/share/keyrings/ros-archive-keyring.gpg
  RUN echo "deb [arch=arm64 signed-by=/usr/share/keyrings/ros-archive-keyring.gpg] \
      http://packages.ros.org/ros2/ubuntu jammy main" \
      > /etc/apt/sources.list.d/ros2.list
  RUN apt update && apt install -y ros-humble-ros-base ros-humble-cv-bridge \
      ros-humble-image-transport ros-humble-v4l2-camera python3-colcon-common-extensions

  # Install vision packages
  RUN apt install -y python3-opencv python3-pip
  RUN pip3 install ultralytics  # YOLOv8

Docker run with hardware access:

  docker run -it --rm \
    --privileged \
    -v /dev:/dev \
    -v /sys:/sys \
    --device /dev/video0 \
    --device /dev/gpiochip0 \
    wyzecar-ros2

================================================================================
                       HUMAN DETECTION OPTIONS
================================================================================

OPTION 1: YOLOv8-nano (Recommended)
-----------------------------------
  - Lightweight, fast on ARM
  - Can use i.MX95 NPU for acceleration
  - Good accuracy for person detection
  - ~20-30 FPS on Cortex-A55

OPTION 2: MobileNet-SSD
-----------------------
  - Very lightweight
  - Lower accuracy but faster
  - Well-supported on edge devices

OPTION 3: MediaPipe Pose/Holistic
---------------------------------
  - Google's ML pipeline
  - Good for tracking specific person
  - Provides skeleton/pose data

OPTION 4: Custom trained model
------------------------------
  - Train on specific use case
  - Optimize for i.MX95 NPU

================================================================================
                       IMPLEMENTATION PHASES
================================================================================

PHASE 1: Basic Setup
--------------------
[ ] Verify Debian boots on Dart MX95
[ ] Set up Docker with Ubuntu 22.04
[ ] Install ROS2 Humble in container
[ ] Test camera capture (v4l2 or MIPI)
[ ] Identify available GPIO/PWM pins

PHASE 2: Motor Control
----------------------
[ ] Create motor_controller_node
[ ] Implement PWM control for L298N
[ ] Implement PWM control for servo
[ ] Test with /cmd_vel messages
[ ] Tune speed/steering response

PHASE 3: Vision Pipeline
------------------------
[ ] Create camera_node
[ ] Create human_detector_node
[ ] Test detection accuracy/speed
[ ] Optimize for NPU if available

PHASE 4: Following Logic
------------------------
[ ] Create follower_node
[ ] Implement PID following controller
[ ] Test target tracking
[ ] Add safety features (obstacle stop, lost target)

PHASE 5: Integration & Tuning
-----------------------------
[ ] Full system test
[ ] Tune PID parameters
[ ] Optimize latency
[ ] Add recovery behaviors

================================================================================
                       RESOURCES
================================================================================

Variscite DART-MX95 Wiki:
  https://dev.variscite.com/dart-mx95/

ROS2 Humble Documentation:
  https://docs.ros.org/en/humble/

ros2_control (diff drive):
  https://control.ros.org/humble/doc/ros2_controllers/diff_drive_controller/doc/userdoc.html

YOLOv8 (Ultralytics):
  https://docs.ultralytics.com/

Linux PWM sysfs:
  https://trac.gateworks.com/wiki/linux/pwm

v4l2_camera ROS2 package:
  https://github.com/ros-drivers/ros2_v4l2_camera

================================================================================
                       NEXT STEPS
================================================================================

1. Confirm carrier board model (Sonata vs other)
2. Boot Debian, check /sys/class/pwm/ for available PWMs
3. Check /dev/video* for camera
4. Map GPIO pins from Sonata schematic
5. Start with Phase 1 implementation

================================================================================
